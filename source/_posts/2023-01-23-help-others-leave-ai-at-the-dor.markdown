---
layout: post
title: "Want to help others? Leave your AI at the door"
description: "Answers generated by AI, like ChatGPT, are often wrong."
date: 2023-01-23 00:00:00
date_formatted: "January 23, 2023"
author: Paulus Schoutsen
comments: true
categories: Public-Service-Announcement
---

Today we're introducing a new rule for the Home Assistant community: it's no longer allowed to use ChatGPT or other AI systems to help others.

Although these systems generate elaborate and well structured answers, they are wrong. Often they are wrong in subtle ways which only someone with the right expertise could detect. And those people wouldn't need AI to have written that answer.

We appreciate that people want to help others, but if you don't have the knowledge, leave it to someone else. Giving an incorrect answer makes things worse. You are wasting everybody's time, including the person asking the question. Trying out an answer that doesn't work is frustrating because you think you're doing something wrong.

Therefore, from now on, the rules for answering questions in the Home Assistant community will be amended with the following:

   * If you respond to someone by simply asking the question to ChatGPT and then reposting whatever it says unsourced and untested you’ll be banned.
   * Same as above but you attribute it to ChatGPT you’ll be warned to stop doing that
   * If you respond by saying “go ask ChatGPT” you’ll be warned to stop doing that. Since that is basically the same as #2 (sharing exactly what ChatGPT says in response but attributed to ChatGPT)
   * If you go ask ChatGPT, review the response, test it, correct the flaws (if any) and then post a working solution - no problem
 

If AI systems get better, we will revisit this rule.
